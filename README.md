# ğŸ“š Book Reader Chatbot

A powerful, AI-driven PDF chatbot that allows users to upload academic or technical PDFs and ask intelligent, context-aware questions about their content â€” all through an elegant and responsive web interface.

---

## ğŸš€ Features

- ğŸ“¤ Upload and parse PDF documents  
- ğŸ’¬ Ask contextual questions to the chatbot  
- âš™ï¸ Uses sentence transformers and vector search for document embeddings  
- ğŸ§  Integrates with LLMs (Google Gemini Pro or replaceable backend)  
- ğŸŒ™ Toggle between light/dark theme with modern gradients  
- ğŸ“ˆ Animated progress bar for upload status  
- ğŸª„ Refined UI with smooth transitions and typing indicators  
- ğŸ” Displays most relevant lines from PDF on the side  

---

## ğŸ›  Tech Stack

| Frontend        | Backend        | ML/NLP & Tools              |
|----------------|----------------|-----------------------------|
| HTML, CSS (custom), JS | Flask (Python) | Sentence Transformers |
| Font Awesome Icons | REST API | FAISS / ChromaDB |
| Google Fonts | File Upload (PDF) | Google Gemini API* |

> *You can run the app without Gemini by modifying `processing.py`.

---

## ğŸ“ Project Structure

```
ğŸ“¦ Book Reader Chatbot
â”œâ”€â”€ app.py                  # Flask backend
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ processing.py       # PDF parsing, embeddings, and LLM logic
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Main UI page
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css           # All styling (including animations and themes)
â”œâ”€â”€ uploads/                # Temporarily stored PDFs
â”œâ”€â”€ .env                    # Your API key (not tracked by Git)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ .gitignore              # Ignore environment, .env, uploads, etc.
```

---

## ğŸ§ª How It Works

1. **Upload PDF**  
   â†’ PDF is parsed and broken down into clean text segments.

2. **Vector Embedding**  
   â†’ Sentences are embedded using `sentence-transformers`.

3. **Vector Indexing**  
   â†’ ChromaDB/FAISS indexes the vectors for efficient retrieval.

4. **Ask Questions**  
   â†’ The most relevant chunk is retrieved and passed to LLM to generate response.

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/HimanshuPatil2001/Book_reader_chatbot.git
cd Book_reader_chatbot
```

### 2. Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate  # On Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Set Up `.env`

Create a `.env` file and paste:

```
GEMINI_API_KEY=your_google_gemini_api_key_here
```

> Or comment out Gemini code if not using it.

### 5. Run the App

```bash
python app.py
```

Then open:  
ğŸ‘‰ **http://127.0.0.1:5000/**

---

## ğŸ“Œ Optional Improvements

- Switch from Gemini to local LLM (like Llama 3)
- Save chat history per user
- Authenticated sessions
- PDF highlight mapping to answers

---

## ğŸ“ƒ License

MIT License â€” Free to use and modify

---

## ğŸ™‹â€â™‚ï¸ Author

**Himanshu Patil**  
ğŸ“ [GitHub Profile](https://github.com/HimanshuPatil2001)